Download tomcat 8 and unzip it into some folder
Open eclipse and create a new project-> dynamic web project
In WebContent folder create a index.html with a script section for java script
Create three json files in WebContent folder with some dummy data (1.json, 2.json, 3.json)
In script section, write an ajax call to load 1.json.
Upon completion load 2.json and upon completion load 3.json
Right click project -> run as -> run on server.
Configure tomcat by specifying home directory and run
------------------
Create a maven project and setup dependencies to vertx

		<dependency>
			<groupId>io.vertx</groupId>
			<artifactId>vertx-web</artifactId>
			<version>3.0.0</version>
		</dependency>
Create a verticle, deploy and run

public class MyVerticle extends AbstractVerticle {

    @Override
    public void start(Future<Void> startFuture) {
        System.out.println("MyVerticle started!");
    }

    @Override
    public void stop(Future stopFuture) throws Exception {
        System.out.println("MyVerticle stopped!");
    }

}

public static void main(String[] args) {
		VertxOptions options = new VertxOptions().setWorkerPoolSize(10);
		Vertx vertx = Vertx.vertx(options);
		vertx.deployVerticle("com.mydomain.MyVerticle");
}

--------------------
Deploy another verticle and setup communication

Here is how we sequence verticle deployment
vertx.deployVerticle("com.mydomain.MyVerticle",new Handler<AsyncResult<String>>() {
		    @Override
		    public void handle(AsyncResult<String> stringAsyncResult) {
		        System.out.println("Verticle deployment complete");
		        }
		    });
		    
Here is how we register and send messages:

vertx.eventBus().consumer("Channel1", message -> {
       System.out.println("message.body() = "
                + message.body());
});
vertx.eventBus().publish("Channel1", "message 2");

---------------------
http://10.169.20.164/Cxwebinterface/odata/v1/Results?$filter=ScanId%20eq%201000000&$expand=Query%28$expand=QueryCxDescription%29
Create a basic http responder:

While deploying the verticle:
HttpServer server = vertx.createHttpServer();
Router router = Router.router(vertx);
router.get("/services/users/:id").handler(new UserLoader());
server.requestHandler(router::accept).listen(8080);


In handler:
String id = routingContext.request().getParam(“id”);
HttpServerResponse response = routingContext.response();
response.putHeader("content-type", “application/json");
response.end(jsonresponse)		

----------------------

Start building a full rest API:
Here is how we handle body data in vertx

restAPI.route().handler(BodyHandler.create());

restAPI.post("/user").handler(rc -> {
	String jsonStr = rc.getBodyAsString();
			.....
	
	ObjectMapper mapper = new ObjectMapper();
    UserDTO dto = mapper.readValue(jsonStr, UserDTO.class);		
    
Here is how we would create a json string for response

            ObjectMapper mapper = new ObjectMapper();
			JsonNode node = mapper.valueToTree(dto);
			response.end(node.toString());
----------------------

Get this app to serve static content by adding this:

router.route().handler(StaticHandler.create()::handle);

Create webroot folder under src/main/resources and copy an index.html in there
access it with : localhost:8080/index.html

Move yesterday's javascript code in there
----------------------

Try promises in jquery in the index.html

$.get() method returns a promise that has the following functions 
done(successfunc)
fail(failurefunc)
always(alwaysfunc)

And has a chaining function called 
then(successfunc, failurefunc)

Use the then() function to make the three json calls

var name="";
	$.get("one.json")
	.then(function(data){
		name = name + data.name+" ";
		return $.get("two.json");
	}).then(function(data2){
		name = name + data2.name+" ";
		return $.get("three.json");
	}).then(function(data3){
		name = name + data3.name+" ";
		console.log(name);
	})
	
---------------------
	
Try parallel execution

below function takes a bunch of promises and resolves them together
$.when(prom1, prom2, prom3).done(function(d1,d2,d3){})










	var onePromise = $.get("one.json");
	var twoPromise = $.get("two.json");
	var threePromise = $.get("three.json");
	
	$.when(onePromise, twoPromise, threePromise).done(function(data1, data2, data3) {
		//Returns an array of data, success/failure status, XHR object
		console.log(data1[0].name+" "+data2[0].name+" "+data3[0].name);	
	}).fail(function(data1,data2,data3) {
		console.log(data1+" "+data2+" "+data3);
	}) 

git remote add origin https://github.com/maruthirj/vertxrepo.git
git push -u origin master
---------------------

Run this on a container.

Create a 'Dockerfile' in the project root that will bundle the built archive into a container

# Extend vert.x image
FROM vertx/vertx3

#                                                       
ENV VERTICLE_NAME com.mydomain.myapp.RestAppVerticle
ENV VERTICLE_FILE target/VertxREST-0.0.1-SNAPSHOT.jar

# Set the location of the verticles
ENV VERTICLE_HOME /usr/verticles

EXPOSE 8080

# Copy your verticle to the container                   
COPY $VERTICLE_FILE $VERTICLE_HOME/

# Launch the verticle
WORKDIR $VERTICLE_HOME
ENTRYPOINT ["sh", "-c"]
CMD ["vertx run $VERTICLE_NAME -cp $VERTICLE_HOME/*"]

------------
Add this to pom.xml for building:
<build>
    <plugins>
      <plugin>
        <artifactId>maven-compiler-plugin</artifactId>
        <version>3.5.1</version>
        <configuration>
          <source>1.8</source>
          <target>1.8</target>
        </configuration>
      </plugin>
    </plugins>
  </build>

------------
Commit everything to github
Pull into a folder on the container

Now run these commands to build an image and run the container

docker build --tag restvertx .
docker run -p 8080:8080 restvertx &

http://<container ip address>:8080/api/user/2

When done

docker stop restvertx

-----------------------------

Fix up the REST api with mongodb backend
Pickup ServicesFactory and User.java from github shared url.

Here is how to use it:
Datastore dataStore = ServicesFactory.getMongoDB();
dataStore.save(u);

ObjectId oid = null;
try {
		oid = new ObjectId(id);
	} catch (Exception e) {// Ignore format errors
	}
List<User> users = dataStore.createQuery(User.class).field("id")
				.equal(oid).asList();
				
		<dependency>
			<groupId>org.mongodb</groupId>
			<artifactId>mongo-java-driver</artifactId>
			<version>3.0.1</version>
		</dependency>
		<dependency>
			<groupId>org.mongodb.morphia</groupId>
			<artifactId>morphia</artifactId>
			<version>1.0.0-rc0</version>
		</dependency>
				
public void handle(RoutingContext routingContext) {
		System.out.println("Thread UserPersister: " + Thread.currentThread().getId());
		// This handler will be called for every request
		HttpServerResponse response = routingContext.response();
		routingContext.request().bodyHandler(new Handler<Buffer>() {
			public void handle(Buffer buf) {
				String json = buf.toString("UTF-8");
				ObjectMapper mapper = new ObjectMapper();
				UserDTO dto = null;
				try {
					dto = mapper.readValue(json, UserDTO.class);
				} catch (IOException e) {
					e.printStackTrace();
				}
				User u = dto.toModel();
				Datastore dataStore = ServicesFactory.getMongoDB();
				dataStore.save(u);
				response.setStatusCode(204).end("Data saved");
			};
		});
	}
	
	public void handle(RoutingContext routingContext) {
		// This handler will be called for every request
		HttpServerResponse response = routingContext.response();
		String id = routingContext.request().getParam("id");

		response.putHeader("content-type", "application/json");
		Datastore dataStore = ServicesFactory.getMongoDB();
		ObjectId oid = null;
		try {
			oid = new ObjectId(id);
		} catch (Exception e) {// Ignore format errors
		}
		List<User> users = dataStore.createQuery(User.class).field("id").equal(oid).asList();
		if (users.size() != 0) {
			UserDTO dto = new UserDTO().fillFromModel(users.get(0));
			ObjectMapper mapper = new ObjectMapper();
			JsonNode node = mapper.valueToTree(dto);
			response.end(node.toString());
		} else {
			response.setStatusCode(404).end("not found");
		}
	}
Once this is working ok, move these into blocking code executors.

------------------------------
** DepositVerticle. 
Two APIs
“/account/:accountNumber" - post and get account with balance info
fields for add: AccountNumber 
fields for get: AccountNumber, balance

/account/:accountNumber/money - add money
Input: AccountNumber, Amount

Implement rest end points that persist info to mongo
Raises event with money object after persisted on depositInfo bus

** CustomerClassificationVerticle
Registers a subscriber on 2 event buses.
depositInfo - Money object is received here
custInfo - Customer Object is received here

Persists this info after computation. 
Class A = Customers with with Deposit > 50000 AND age < 45
Class B = Customers with with Deposit > 50000 AND age > 45

** CustomerInfoVerticle

/customer POST and GET
customer fields: name, age, profession, accountnumber

Raises event with customer object after persisted on custInfo bus
-------------------------------
POM to use:

		<dependency>
			<groupId>io.vertx</groupId>
			<artifactId>vertx-mongo-client</artifactId>
			<version>3.2.1</version>
		</dependency>
		<dependency>
			<groupId>com.fasterxml.jackson.core</groupId>
			<artifactId>jackson-core</artifactId>
			<version>2.7.4</version>
		</dependency>
		<dependency>
			<groupId>io.vertx</groupId>
			<artifactId>vertx-hazelcast</artifactId>
			<version>3.2.1</version>
		</dependency>
---------------------------------
These will be created as 3 different eclipse projects
In the root of these projects place the Dockerfile and logging.properties from share
In src/main/resources, place the cluster.xml from share
In each project edit the cluster.xml to change port numbers 5701, 5702, 5703
DepositVerticle should run on 8080 and CustInfo on 8090 (Server listen)

Docker commands to build these containers

mvn package
docker build -t deposit .
docker run -i -p 8080:8080 -p 5701:5701 --name r_deposit deposit

mvn package
docker build -t custclass .
docker run -i -p 5703:5703 --name r_custclass custclass
-----------------
For HA proxy, pick up the haproxy.cfg and put it in a folder
In the same folder create a Dockerfile with this content:

FROM haproxy:1.5
COPY haproxy.cfg /usr/local/etc/haproxy/haproxy.cfg

Then build and run:
docker build -t proxy .
docker run -d -p 80:80 --name running_proxy proxy

A useful script to stop and cleanup all containers stopAll.sh:
——————————————-
docker stop r_custclass
docker stop r_deposit
docker stop r_custinfo
docker rm r_custclass
docker rm r_deposit
docker rm r_custinfo
docker rmi custclass
docker rmi custinfo
docker rmi deposit
------------------------------------

Start all containers:
mongo,deposit,custclassification,haproxy

Access the deposit API via <VM host>:80































